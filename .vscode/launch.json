{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "gen obj",
            "type": "debugpy",
            "request": "launch",
            "program": "./muffin/eval/muffin_vqa.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--model-path", "liuhaotian/llava-v1.5-7b",
                "--question-file", "./eval/data/obj_halbench_300_with_image.jsonl",
                "--answers-file", "./result/llava/obj_halbench_answer.jsonl",
                "--temperature", "0",
                "--num_beam", "3"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "eval obj",
            "type": "debugpy",
            "request": "launch",
            "program": "./eval/eval_gpt_obj_halbench.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--coco_path", "eval/annotations",
                "--cap_folder", "result/llava",
                "--cap_type", "obj_halbench_answer.jsonl",
                "--org_folder", "./eval/data/obj_halbench_300_with_image.jsonl",
                "--use_gpt",
                "--openai_key", "ads4"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "gen mmh",
            "type": "debugpy",
            "request": "launch",
            "program": "./muffin/eval/muffin_vqa.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--model-path", "liuhaotian/llava-v1.5-7b",
                "--question-file", "./eval/data/mmhal-bench_with_image.jsonl",
                "--answers-file", "./result/llava/mmhal-bench_answer.jsonl",
                "--temperature", "0",
                "--num_beam", "3"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "eval mmh",
            "type": "debugpy",
            "request": "launch",
            "program": "./eval/eval_gpt_mmhal.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--response", "result/llava/mmhal-bench_answer.jsonl",
                "--evaluation", "result/llava/mmhal-bench_answer.jsonl.mmhal_test_eval.json",
                "--gpt-model", "$gpt_model",
                "--api-key", "ads",
                "--is_jsonl"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "vis obj",
            "type": "debugpy",
            "request": "launch",
            "program": "eval/vis_obj.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                // "--model-path", "liuhaotian/llava-v1.5-7b",
                // "--question-file", "./eval/data/obj_halbench_300_with_image.jsonl",
                // "--answers-file", "./result/llava/obj_halbench_answer.jsonl",
                // "--temperature", "0",
                // "--num_beam", "3"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "rlaif",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/mnt/share_server/miniconda3/envs/mmlm/bin/deepspeed",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            },
            "args": [
                "${workspaceFolder}/muffin/train/train_llava15_lora.py",
                "--deepspeed",
                "script/zero2.json",
                "--model_name_or_path",
                "liuhaotian/llava-v1.5-7b",
                "--data_dir",
                "./RLAIF-V-Dataset_logps/",
                "--image_folder",
                "not_used",
                "--vision_tower",
                "openai/clip-vit-large-patch14-336",
                "--mm_use_im_start_end",
                "False",
                "--mm_use_im_patch_token",
                "False",
                "--fully_tune",
                "False",
                "--image_aspect_ratio",
                "pad",
                "--bf16",
                "True",
                "--mm_projector_type",
                "mlp2x_gelu",
                "--mm_vision_select_layer",
                "-2",
                "--output_dir",
                "${workspaceFolder}/.ckpt/llava15_7b_DPO-llava15_rlaifv_lora/checkpoints",
                "--num_train_epochs",
                "10",
                "--per_device_train_batch_size",
                "8",
                "--per_device_eval_batch_size",
                "4",
                "--gradient_accumulation_steps",
                "1",
                "--evaluation_strategy",
                "no",
                "--save_strategy",
                "steps",
                "--save_steps",
                "16710",
                "--save_total_limit",
                "50",
                "--data_source_names",
                "",
                "--data_source_weights",
                "1",
                "--max_steps",
                "26720",
                "--learning_rate",
                "1e-5",
                "--weight_decay",
                "0.01",
                "--warmup_ratio",
                "0.05",
                "--lr_scheduler_type",
                "cosine",
                "--logging_steps",
                "2",
                "--logging_dir",
                "${workspaceFolder}/.ckpt/llava15_7b_DPO-llava15_rlaifv_lora/log",
                "--tf32",
                "True",
                "--model_max_length",
                "2048",
                "--gradient_checkpointing",
                "True",
                "--lazy_preprocess",
                "True",
                "--task",
                "DPO",
                "--report_to",
                "wandb",
                "--run_name",
                "llava15_rlaifv_lora",
                "--dataloader_num_workers",
                "16",
                "--dpo_use_average",
                "False",
                "--dpo_token_weighted",
                "False",
                "--dpo_token_weight",
                "1.0",
                "--dpo_beta",
                "0.1",
                "--lora_enable",
                "True"
            ]
        }
    ]
}