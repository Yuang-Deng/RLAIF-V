{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "score cal",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/mnt/share_server/miniconda3/envs/mmlm/bin/deepspeed",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "./our_works/score_cal.py"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "resp gen batch",
            "type": "debugpy",
            "request": "launch",
            "program": "./our_works/resp_gen_batch.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--model-path",
                "liuhaotian/llava-v1.5-7b",
                "--question-file",
                "./eval/data/mmhal-bench_with_image.jsonl",
                "--answers-file",
                "./result/RLAIF-V-7B-test/mmhal-bench_answer.jsonl",
                "--temperature",
                "0",
                "--num_beam",
                "3"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "model merge",
            "type": "debugpy",
            "request": "launch",
            "program": "./our_works/model_merge.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "logit gen",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/mnt/share_server/miniconda3/envs/mmlm/bin/deepspeed",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "muffin/train/train_llava15_test.py",
                "--deepspeed",
                "script/zero2.json",
                "--model_name_or_path",
                "liuhaotian/llava-v1.5-7b",
                "--data_dir",
                "./RLAIF-V-Dataset_logps/",
                "--image_folder",
                "not_used",
                "--vision_tower",
                "openai/clip-vit-large-patch14-336",
                "--mm_use_im_start_end",
                "False",
                "--mm_use_im_patch_token",
                "False",
                "--fully_tune",
                "False",
                "--image_aspect_ratio",
                "pad",
                "--bf16",
                "True",
                "--mm_projector_type",
                "mlp2x_gelu",
                "--mm_vision_select_layer",
                "-2",
                "--output_dir",
                "${workspaceFolder}/.ckpt/llava15_7b_DPO-llava15_rlaifv_lora/checkpoints",
                "--num_train_epochs",
                "10",
                "--per_device_train_batch_size",
                "16",
                "--per_device_eval_batch_size",
                "4",
                "--gradient_accumulation_steps",
                "1",
                "--evaluation_strategy",
                "no",
                "--save_strategy",
                "steps",
                "--save_steps",
                "16710",
                "--save_total_limit",
                "50",
                "--data_source_names",
                "",
                "--data_source_weights",
                "1",
                "--max_steps",
                "26720",
                "--learning_rate",
                "1e-5",
                "--weight_decay",
                "0.01",
                "--warmup_ratio",
                "0.05",
                "--lr_scheduler_type",
                "cosine",
                "--logging_steps",
                "2",
                "--logging_dir",
                "${workspaceFolder}/.ckpt/llava15_7b_DPO-llava15_rlaifv_lora/log",
                "--tf32",
                "True",
                "--model_max_length",
                "2048",
                "--gradient_checkpointing",
                "True",
                "--lazy_preprocess",
                "True",
                "--task",
                "DPO",
                "--report_to",
                "wandb",
                "--run_name",
                "llava15_rlaifv_lora",
                "--dataloader_num_workers",
                "16",
                "--dpo_use_average",
                "False",
                "--dpo_token_weighted",
                "False",
                "--dpo_token_weight",
                "1.0",
                "--dpo_beta",
                "0.1",
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "gen mathvista",
            "type": "debugpy",
            "request": "launch",
            "program": "our_works/mathvista/eval.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--model-path",
                ".ckpt/llava15_7b_DPO-llava15_rlaifv_lora_1w1_tao/checkpoints",
                "--model-base",
                ".ckpt/llava15_7b_DPO-llava15_rlaifv_lora_merged",
                // "--model-base",
                // "None",
                "--model-name",
                "llava-v1.5-7b_lora",
                "--question-file",
                "./eval/data/obj_halbench_300_with_image.jsonl",
                "--answers-file",
                "./result/RLAIF-V-7B-lora-1w1_tao/mathvista.jsonl",
                "--temperature",
                "0",
                "--num_beam",
                "3"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "gen obj",
            "type": "debugpy",
            "request": "launch",
            "program": "./muffin/eval/muffin_vqa.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--model-path",
                ".ckpt/llava15_7b_DPO-llava15_rlaifv_lora_4w_mpo_0.3/checkpoints",
                "--model-base",
                "liuhaotian/llava-v1.5-7b",
                "--model-name",
                "llava-v1.5-7b_lora",
                "--question-file",
                "./eval/data/obj_halbench_300_with_image.jsonl",
                "--answers-file",
                "./result/4w_mpo_0.3/obj_halbench_answer.jsonl",
                "--temperature",
                "0",
                "--num_beam",
                "3"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "eval obj",
            "type": "debugpy",
            "request": "launch",
            "program": "./eval/eval_gpt_obj_halbench.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--coco_path",
                "eval/annotations",
                "--cap_folder",
                "./result/4w_mpo_0.3_nodpo",
                "--cap_type",
                "obj_halbench_answer.jsonl",
                "--org_folder",
                "./eval/data/obj_halbench_300_with_image.jsonl",
                "--use_gpt",
                "--openai_key",
                "ads4"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "sum obj",
            "type": "debugpy",
            "request": "launch",
            "program": "./eval/summarize_gpt_obj_halbench_review.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "./result/4w_mpo_0.3_nodpo"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "gen mmh",
            "type": "debugpy",
            "request": "launch",
            "program": "./muffin/eval/muffin_vqa.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                // "--model-path",
                // "liuhaotian/llava-v1.5-7b",
                // "--model-base",
                // "None",
               "--model-path",
                ".ckpt/llava15_7b_DPO-llava15_rlaifv_lora_4w_mpo/checkpoints",
                "--model-base",
                "liuhaotian/llava-v1.5-7b",
                "--model-name",
                "llava-v1.5-7b_lora",
                "--question-file",
                "./eval/data/mmhal-bench_with_image.jsonl",
                "--answers-file",
                "./result/4w_mpo/mmhal-bench_answer.jsonl",
                "--temperature",
                "0",
                "--num_beam",
                "3"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "eval mmh",
            "type": "debugpy",
            "request": "launch",
            "program": "./eval/eval_gpt_mmhal.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--response",
                "result/4w_mpo/mmhal-bench_answer.jsonl",
                "--evaluation",
                "result/4w_mpo/mmhal-bench_answer.jsonl.mmhal_test_eval.json",
                "--gpt-model",
                "$gpt_model",
                "--api-key",
                "ads",
                "--is_jsonl"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "sum mmh",
            "type": "debugpy",
            "request": "launch",
            "program": "./eval/summarize_gpt_mmhal_review.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "./result/1w1_2k"
            ],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "vis obj",
            "type": "debugpy",
            "request": "launch",
            "program": "eval/vis_obj.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "vis mmhl",
            "type": "debugpy",
            "request": "launch",
            "program": "eval/vis_mmhl.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "data split",
            "type": "debugpy",
            "request": "launch",
            "program": "our_works/dataset_split.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [],
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            }
        },
        {
            "name": "rlaif",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/mnt/share_server/miniconda3/envs/mmlm/bin/deepspeed",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            },
            "args": [
                "${workspaceFolder}/muffin/train/train_llava15_lora.py",
                "--deepspeed",
                "script/zero2.json",
                "--model_name_or_path",
                ".ckpt/llava15_7b_DPO-llava15_rlaifv_lora_3k1_from_4w_merged",
                "--data_dir",
                "./splited_dataset/1w1_3k1_from_4w_theta/",
                "--image_folder",
                "not_used",
                "--vision_tower",
                "openai/clip-vit-large-patch14-336",
                "--mm_use_im_start_end",
                "False",
                "--mm_use_im_patch_token",
                "False",
                "--fully_tune",
                "False",
                "--image_aspect_ratio",
                "pad",
                "--bf16",
                "True",
                "--mm_projector_type",
                "mlp2x_gelu",
                "--mm_vision_select_layer",
                "-2",
                "--output_dir",
                "${workspaceFolder}/.ckpt/llava15_7b_DPO-llava15_rlaifv_lora_1w1_3k1_from_4w_theta/checkpoints",
                "--num_train_epochs",
                "10",
                "--per_device_train_batch_size",
                "8",
                "--per_device_eval_batch_size",
                "4",
                "--gradient_accumulation_steps",
                "1",
                "--evaluation_strategy",
                "no",
                "--save_strategy",
                "steps",
                "--save_steps",
                "1250",
                "--save_total_limit",
                "50",
                "--data_source_names",
                "",
                "--data_source_weights",
                "1",
                "--max_steps",
                "2500",
                "--learning_rate",
                "1e-5",
                "--weight_decay",
                "0.01",
                "--warmup_ratio",
                "0.05",
                "--lr_scheduler_type",
                "cosine",
                "--logging_steps",
                "2",
                "--logging_dir",
                "${workspaceFolder}/.ckpt/llava15_7b_DPO-llava15_rlaifv_lora_1w1_3k1_from_4w_theta/${workspaceFolderBasename}/log",
                "--tf32",
                "True",
                "--model_max_length",
                "2048",
                "--gradient_checkpointing",
                "True",
                "--lazy_preprocess",
                "True",
                "--task",
                "DPO",
                "--report_to",
                "wandb",
                "--run_name",
                "llava15_rlaifv_lora",
                "--dataloader_num_workers",
                "16",
                "--dpo_use_average",
                "False",
                "--dpo_token_weighted",
                "False",
                "--dpo_token_weight",
                "1.0",
                "--dpo_beta",
                "0.1",
                "--lora_enable",
                "True"
            ]
        },
        {
            "name": "mpo",
            "type": "debugpy",
            "request": "launch",
            "program": "/home/mnt/share_server/miniconda3/envs/mmlm/bin/deepspeed",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}"
            },
            "args": [
                "${workspaceFolder}/muffin/train/train_llava15_lora_MPO.py",
                "--deepspeed",
                "script/zero2.json",
                "--model_name_or_path",
                "liuhaotian/llava-v1.5-7b",
                "--delta",
                "0.3",
                "--data_dir",
                "./splited_dataset/4w1",
                "--image_folder",
                "not_used",
                "--vision_tower",
                "openai/clip-vit-large-patch14-336",
                "--mm_use_im_start_end",
                "False",
                "--mm_use_im_patch_token",
                "False",
                "--fully_tune",
                "False",
                "--image_aspect_ratio",
                "pad",
                "--bf16",
                "True",
                "--mm_projector_type",
                "mlp2x_gelu",
                "--mm_vision_select_layer",
                "-2",
                "--output_dir",
                "${workspaceFolder}/.ckpt/llava15_7b_DPO-llava15_rlaifv_lora_4w_mpo_0.3_nodpo/checkpoints",
                "--num_train_epochs",
                "10",
                "--per_device_train_batch_size",
                "8",
                "--per_device_eval_batch_size",
                "4",
                "--gradient_accumulation_steps",
                "1",
                "--evaluation_strategy",
                "no",
                "--save_strategy",
                "steps",
                "--save_steps",
                "5000",
                "--save_total_limit",
                "50",
                "--data_source_names",
                "",
                "--data_source_weights",
                "1",
                "--max_steps",
                "10000",
                "--learning_rate",
                "1e-5",
                "--weight_decay",
                "0.01",
                "--warmup_ratio",
                "0.05",
                "--lr_scheduler_type",
                "cosine",
                "--logging_steps",
                "2",
                "--logging_dir",
                "${workspaceFolder}/.ckpt/llava15_7b_DPO-llava15_rlaifv_lora_4w_mpo_0.3_nodpo/${workspaceFolderBasename}/log",
                "--tf32",
                "True",
                "--model_max_length",
                "2048",
                "--gradient_checkpointing",
                "True",
                "--lazy_preprocess",
                "True",
                "--task",
                "DPO",
                "--report_to",
                "wandb",
                "--run_name",
                "llava15_rlaifv_lora",
                "--dataloader_num_workers",
                "16",
                "--dpo_use_average",
                "False",
                "--dpo_token_weighted",
                "False",
                "--dpo_token_weight",
                "1.0",
                "--dpo_beta",
                "0.1",
                "--lora_enable",
                "True"
            ]
        }
    ]
}